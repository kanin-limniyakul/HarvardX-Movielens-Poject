---
pdf_document:
  fig_caption: yes
  number_sections: yes
  toc: yes
  df_print: kable
author: "_Kanin Limniyakul_"
date: "3/31/2022"
output:
  pdf_document: default
title: '**MovieLens Recommendation System Project**'
subtitle: 'HarvardX Data Science Professional Certificate: PH125.9x Capstone 1'
---

```{r , include=FALSE, cache = TRUE}
knitr::opts_chunk$set(echo = TRUE)
tinytex::install_tinytex()
```

\newpage
\tableofcontents 
\listoffigures
\listoftables
\newpage


# Executive Summary

This is the a part of HarvardX professional certificate in Data Science capstone project.The target of the project is to predict movie ratings from 10 million MovieLens dataset which trying to minimize the root mean square estimate (RMSE) of the validation set as much as possible. The report started from performing the exploratory analysis (EDA) to see the bias effects on each parameters including movies, users, genres and released year.

Then we built a linear model from the naive model (simple average all the rating) then add each effect parameters except released year (it's has a little effect on the ratings). The training set RSME is gradually reduced from 1.0601524 to 0.8650721. After that the regularized method was used to control the variance of effects size so the RSME is finally reduced to 0.8650721. 

Matrix Factorization is another methodology used in this report, the basic concept is to reshape the matrix size of 9,000,055 x 6 to be 69,878 x 10,677 and use recosystem library to estimate the rating. the training RMSE is 0.7909077. 


The final validation test is conducted  and got the final the linear model RSME of 0.8644514 and the final matrix factorization model is 0.7830619.


```{r setup, echo =FALSE, message = FALSE}
##########################################################
# Create edx set, validation set (final hold-out test set)
##########################################################

# Note: this process could take a couple of minutes

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")

library(tidyverse)
library(caret)
library(data.table)
library(lubridate)


```

```{r data partitioning, echo =FALSE, cache = TRUE, warning=FALSE, message =FALSE}
# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")

# if using R 3.6 or earlier:
#movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],
                                           #title = as.character(title),
                                           #genres = as.character(genres))
# if using R 4.0 or later:
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(movieId),
                                           title = as.character(title),
                                           genres = as.character(genres))


movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data
set.seed(1, sample.kind="Rounding") # if using R 3.5 or earlier, use `set.seed(1)`
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)
```

# Exploratory Data Analysis (EDA)

Firstly, the split movieLens 10M dataset into edx dataset and valiation set. Our edx dataset is further divided into the test set and the training set. The edx dataset comprises of 9,000,055 rows, 6 variables, 69,878 unique users and 10,677 unique movies which means that not all users rated all the movies.

```{r data overview, echo = FALSE}

#str(edx)

edx_sum <- data.frame(np_of_rows = nrow(edx),
                          no_of_column = ncol(edx),
                          no_of_users = n_distinct(edx$userId),
                          no_of_movies = n_distinct(edx$movieId),
                          avg_rating = round(mean(edx$rating),2),
                          no_of_genres = n_distinct(edx$genres))

knitr::kable (edx_sum , caption = "Summary of edx dataset" )

```
## General Rating Information

The movies are rated in the scale of 0 to 5 with the incremental of 0.5. From the below histogram and the table, rating 4 is the majority of the dataset (2,588,430) and average rating of all the movies is 3.512 (red dashed-line).



```{r rating information,  echo= FALSE,  fig.cap="Rating Distribution"}


hist(edx$rating,main ="Rating distribution in edx data set", 
                xlab = "Rating", ylab = "Frequency (n)")
abline(v = mean(edx$rating), col = 'red', lwd=3, lty=2) #mean vertical line


```
```{r rating table summary, echo = FALSE, message=FALSE, warning=FALSE}
rate_sum <- edx %>% group_by(rating) %>% summarize(n())
knitr::kable (rate_sum, caption = "Rating Summary")
```

## General Movies information

There are 10,677 movies in the edx dataset. It is well understandably that some movies have got more numbers of review more than others which could be depending on the popularity. We can see the distribution of no of ratings as below histogram. Pulp fiction (1994) got the highest no of rating of 31,326 and there are 126 movies got 1 rating only. We can see the top 5 number of rating as below,

```{r movies information, echo = FALSE}

movie <- edx %>% group_by(movieId) %>% summarise( n = n()) 

movie_top5 <- movie %>% top_n(5)
knitr::kable (movie_top5, caption = "Top 5 rated movies")



```


```{r histrogram_movie, fig.cap = "Histrogram of ratings for each movies", echo = FALSE}

#histogram of Number of Ratings for each Movies

hist_id_count <- edx %>% 
                 count(movieId) %>% 
                 ggplot(aes(n)) + 
                 geom_histogram(color = "black", bins = 30) + 
                 scale_x_log10() +
                 xlab("movieId") +
                 ylab("Number of Ratings") +
                 labs(title = "Number of Ratings for each movie",
                      caption= "Data Source : edx dataset")
                 
hist_id_count
```

## General User information

Some users are more active than others, we can see the distribution which the minimum no of rating of 10 per user, the most active user reviewed up to 66,616 movies, mean no rating is 128.8 and median of 62 times. In addition, the rating scores are varies across users as well, some users tended to give more rating compare to other users.



```{r users information,  echo = FALSE, fig.cap = " No. of rating per user distribution"}

user <- edx %>% group_by(userId) %>% summarize(n=n(),avg_rating = mean(rating))


hist(user$n, main = "Number of rating per user in edx data set", xlab = "no rating per user", ylab = "Frequency (n)")
abline(v = median(user$n), col = 'blue', lwd=3, lty=2) #median vertical line
abline(v = mean(user$n), col = 'red', lwd=3, lty=2) #mean vertical line



```
```{r,  echo =FALSE, fig.cap = "Average rating disrribution across users"}


edx %>% group_by(userId) %>%
  summarise(avg_rating = sum(rating)/n()) %>%
  ggplot(aes(avg_rating)) +
  geom_histogram(bins=30, color = I("black")) +
  labs(x = "Average rating", y = "Number of users", caption = "Source: edx dataset")+
  labs(title = "Average Ratings Distribution",
       caption= "Data Source : edx dataset")
```


## General Genres Information

From the data, it is observed that some movies genres also vary in terms of number of rating and average rating as per the table and figure below. The table shows the top 10 most reviewed genres. whereas the plot shows the rating average of the movies having more than 150,000 reviews.



```{r genres information, echo = FALSE}

genres <- edx %>% group_by(genres) %>% summarize(no_of_review =n(),avg_rating = mean(rating))

top10_genres <- genres %>% top_n(10,no_of_review) 

knitr::kable (top10_genres, caption = "Top 10 most reviewed genres")

```


```{r genres plot,  echo = FALSE, fig.cap="Average rating by genre (>150,000 reviews)"}


# Plot average rating by genre for genre combinations with at least 150,000 ratings
genres_effect <- edx %>% group_by(genres) %>%
  summarize(n = n(), avg = mean(rating), se = sd(rating)/sqrt(n())) %>%
  filter(n >= 150000) %>% 
  mutate(genres = reorder(genres, avg)) %>%
  ggplot(aes(x = genres, y = avg, ymin = avg - 2*se, ymax = avg + 2*se)) + 
  geom_point() +
  geom_errorbar() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(x = "Genre combination", y = "Average Rating", caption = "Data Source: edx dataset")

genres_effect

```
## General Release date information

From the plot below, there is a little effect on release date but not so strong. The average ratings were in between 3.25 to 4.25.



```{r release date,  echo = FALSE, warning=FALSE, message=FALSE,fig.cap = "Rating vs Release Date"}

edx <- edx %>% mutate(edx, date = as_datetime(timestamp))


edx %>% mutate(date = round_date(date, unit = "week")) %>%
  group_by(date) %>%
  summarize(rating = mean(rating)) %>%
  ggplot(aes(date, rating)) +
  geom_point() +
  geom_smooth()


```


\newpage
# Methodology and Analysis

As we have explored the effects on parameters of movies, users, genres and release date. We will determine the bias from 3 parameters (except time whuch has a little or no effect to ratings.) and then perform regularise analysis on those effects.

## Data partitioning of edx dataset 

Firstly, the edx data set will be divided into the training set (80%) and the test set (20%) as we reserve the validation set for the final hold-out test set. The logic is to provide the sufficient train dataset to train the model

```{r partition train/test set, echo =FALSE, warning=FALSE}
# Create train set and test sets from edx
set.seed(2022, sample.kind = "Rounding")
test_index <- createDataPartition(y = edx$rating, times = 1, p = 0.2, list = FALSE)
train_set <- edx[-test_index,]
tempo <- edx[test_index,]

# Ensure movieId and userID in test set are also in train set
test_set <- tempo %>%
  semi_join(train_set, by = "movieId") %>%
  semi_join(train_set, by = "userId")

# Add rows removed from test set back into train set
removed <- anti_join(tempo, test_set) 
train_set <- rbind(train_set, removed)

# Remove temporary files to tidy environment
rm(test_index, tempo, removed) 
```


## Residual Mean Square Error(RMSE)

Residual Mean Square Error(RMSE) is calculated by the standard deviation of the difference between predicted rating and the actual rating as below equation,

$$RMSE = \sqrt{\frac{1}{N}\sum_{u,i}\left(\hat{y}_{u,i}-y_{u,i}\right)^2}$$

where,

 $y_{u,i}$ is defined as the actual rating provided by user $i$ for movie $u$ <br/>
 $\hat{y}_{u,i}$ is the predicted rating for the same <br/> 
 N is the total number of user/movie combinations <br/>

The goal is this project is to create a machine learing model that can achieve RSME < 0.xxxx

```{r RMSE function, echo = FALSE}
RMSE <- function(true_ratings, predicted_ratings){
  sqrt(mean((true_ratings - predicted_ratings)^2))
}

```

## Simple Model

The first and the very simple method is to average all the movie ratings and apply to all the movies. Not surprisingly the RSME is as high as 1.06152

The first model is shown below,

$$Y_{u,i}=\mu+\epsilon_{u,i}$$  <br/>
where,
$Y_{u,i}$ is the actual rating for movie $i$ by user $u$ <br/>
$\mu$ is the average of all ratings <br/>
$\epsilon_{u,i}$ is independent errors<br/>


```{r Simple model, echo = FALSE, warning=FALSE, message=FALSE}
mu_hat <- mean(train_set$rating)

rmse_simple <- RMSE(test_set$rating, mu_hat)


rmse_results <- data_frame(method = "Average", RMSE = rmse_simple)
knitr::kable (rmse_results, caption = "RSME Results - Simple Average")
```

## Add Movie Effect

As per exploratory data analysis section, movies themselves have their own biases due to the popularity, so we need to add a term to take into account from movies biases. We add b_i into the first model as below,

$$Y_{u,i}=\mu+b_i+\epsilon_{u,i}$$  <br/>
where the added b_i is movie bias


the least square estimate bi can be calculated by the average of $Y_{u,i}-\hat{\mu}$ for each movie $i$

$$\hat{y}_{u,i}=\hat{\mu}+\hat{b}_i$$ 

we can improve our RSME into 0.9435666.

```{r movies effect, echo =FALSE}
mu <- mean(train_set$rating)  
movie_avgs <- train_set %>% 
  group_by(movieId) %>% 
  summarize(b_i = mean(rating - mu))

# Predict ratings adjusting for movie effects

predicted_ratings <- mu + test_set %>% 
  left_join(movie_avgs, by='movieId') %>%
  pull(b_i)



rmse_bi <- RMSE(predicted_ratings, test_set$rating)

rmse_results <- bind_rows(rmse_results, data_frame(method = "Average + b_i", RMSE = rmse_bi))

knitr::kable (rmse_results, caption = "RSME Results - Add Movie Effect")

```


## Add User Effect

Following the same logic as movie effect, the user effect (b_u) to the model 

$$Y_{u,i}=\mu+b_i+b_u+\epsilon_{u,i}$$  <br/>
where the added b_u is user bias

the least square estimate b_u can be calculated by the average of

$$\hat{b}_{u}=mean\left(\hat{y}_{u,i}-\hat{\mu}-\hat{b}_i\right)$$ 

RSME is now further improved into 0.8660905


```{r users effect, echo=FALSE}
user_avgs <- train_set %>% 
  left_join(movie_avgs, by='movieId') %>%
  group_by(userId) %>%
  summarize(b_u = mean(rating - mu - b_i))

# Predict ratings adjusting for movie and user effects
predicted_ratings <- test_set %>% 
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId') %>%
  mutate(pred = mu + b_i + b_u) %>%
  pull(pred)


rmse_bi_bu <- RMSE(predicted_ratings, test_set$rating)

rmse_results <- bind_rows(rmse_results, data_frame(method = "Average + b_i + b_u", RMSE = rmse_bi_bu))

knitr::kable (rmse_results, caption = "RSME Results - Add user effect")

```

## Add Genres Effect

The model is further improved by add genres effect

$$Y_{u,i}=\mu+b_i+b_u+b_g\epsilon_{u,i}$$  <br/>
where the added b_g is genres bias

the least square estimate b_g can be calculated by the average of

$$\hat{b}_{g}=mean\left(\hat{y}_{u,i}-\hat{\mu}-\hat{b}_i-\hat{b}_u\right)$$ 

RMSE is now reduced to 0.8657490.

 
```{r genres effect, echo = FALSE}
genre_avgs <- train_set %>%
  left_join(movie_avgs, by = "movieId") %>%
  left_join(user_avgs, by = "userId") %>%
  group_by(genres) %>%
  summarise(b_g = mean(rating - mu_hat - b_i - b_u))

# Predict ratings adjusting for movie, user and genre effects
predicted_b_g <- test_set %>%
  left_join(movie_avgs, by = "movieId") %>%
  left_join(user_avgs, by = "userId") %>%
  left_join(genre_avgs, by = "genres") %>%
  mutate(pred = mu_hat + b_i + b_u + b_g) %>%
  pull(pred)
# Calculate RMSE based on genre effects model
rmse_bi_bu_bg <- RMSE(predicted_b_g, test_set$rating)
rmse_results <- bind_rows(rmse_results, 
                          data_frame(method = "Average + b_i + b_u + b_g", RMSE = rmse_bi_bu_bg))
knitr::kable (rmse_results, caption = "RSME Results - Add genres effect")

```

## Regularization 

Regularization is to "control" the effect sizes variability. In our dataset in the EDA section, there are some movies got rated many times where as some movies got reviewed only one. SO the equation we try to minimize is as below,

$$\frac{1}{N}\sum_{u,i}\left(y_{u,i}-\mu-b_i\right)^2+\lambda\sum_ib_i^2$$  

Thus, the regularized estimate of b_i is   

$$\hat{b}_i\left(\lambda\right)=\frac{1}{\lambda+n_i}\sum_{u=1}^{n_i}\left(Y_{u,i}-\hat{\mu}\right)$$  

 
The incorporated regularize to all the effects is as below,

$$\frac{1}{N}\sum_{u,i}\left(y_{u,i}-\mu-b_i-b_u-b_g\right)^2+\lambda\left(\sum_ib_i^2+\sum_ub_u^2+\sum_gb_g^2\right)$$ 

The Lampda that yields the lowest RMSE is 4.75.

```{r regularization, echo = FALSE, cache= TRUE}
#Finding the best lamda to yield lowest RMSE

lambdas <- seq(3, 6, 0.25)

rmses <- sapply(lambdas, function(l){
  
  mu <- mean(train_set$rating)
  
  b_i <- train_set %>% 
    group_by(movieId) %>%
    summarize(b_i = sum(rating - mu)/(n()+l))
  
  b_u <- train_set %>% 
    left_join(b_i, by="movieId") %>%
    group_by(userId) %>%
    summarize(b_u = sum(rating - b_i - mu)/(n()+l))
  
  b_g <- train_set %>%
    left_join(b_i, by="movieId") %>%
    left_join(b_u, by="userId") %>%
    group_by(genres) %>%
    summarise(b_g = sum(rating - b_i - b_u - mu_hat)/(n()+l))
  
  predicted_ratings <- 
    test_set %>% 
    left_join(b_i, by = "movieId") %>%
    left_join(b_u, by = "userId") %>%
    left_join(b_g, by = "genres") %>%
    mutate(pred = mu + b_i + b_u + b_g) %>%
    pull(pred)
  
  return(RMSE(predicted_ratings, test_set$rating))
})

qplot(lambdas, rmses) 
#abline(h = lambdas[which.min(rmses)], col = 'red', lwd=3, lty=2) #mean vertical line


lambda <- lambdas[which.min(rmses)]
lambda

```
The RMSE is now 0.8650722.
```{r regularised table, echo= FALSE}
rmse_regularised <- min(rmses) 
rmse_results <- bind_rows(rmse_results, 
                          data_frame(method = "Regularised average + b_i + b_u + b_g", RMSE = rmse_regularised))
knitr::kable (rmse_results, caption = "RSME Results - Regularised")
```

# Matrix Factorization

The concept of Matrix Factorization is try to reduce the large matrix dimension into the product of two matrices."recosystem" package is used to train the model, find the penalty term, exporting metrices and make prediction.


```{r matrix factorization, echo = FALSE,  cache = TRUE}

if(!require(recosystem)) 
  install.packages("recosystem", repos = "http://cran.us.r-project.org")
set.seed(2022, sample.kind = "Rounding") # This is a randomized algorithm



# Convert the train and test sets into recosystem input format
train_data <-  with(train_set, data_memory(user_index = userId, 
                                           item_index = movieId, 
                                           rating     = rating))
test_data  <-  with(test_set,  data_memory(user_index = userId, 
                                           item_index = movieId, 
                                           rating     = rating))

# Create the model object
r <-  recosystem::Reco()

# Select the best tuning parameters
opts <- r$tune(train_data, opts = list(dim = c(10, 20, 30), 
                                       lrate = c(0.1, 0.2),
                                       costp_l2 = c(0.01, 0.1), 
                                       costq_l2 = c(0.01, 0.1),
                                       nthread  = 4, niter = 10))

# Train the algorithm  
r_train<- r$train(train_data, opts = c(opts$min, nthread = 4, niter = 20))

# Calculate the predicted values  
y_hat_reco <-  r$predict(test_data)
head(y_hat_reco, 10)

RMSE <- function(true_ratings, predicted_ratings){
  sqrt(mean((true_ratings - predicted_ratings)^2))
}

rmse_reco <- RMSE(test_set$rating, y_hat_reco)

rmse_results <- bind_rows(rmse_results, 
                          data_frame(method = "Matrix Factorizarion", RMSE = rmse_reco))
knitr::kable (rmse_results, caption = "RSME Results - Matrix Factorization")


```




# Model Validation

Now the whole edx dataset is used as the training set with lampda (4.75) to test with the final validation set. The final RMSE is 

```{r validation, echo = FALSE, cache=TRUE}
b_i_v <- edx %>% 
  group_by(movieId) %>%
  summarize(b_i_v = sum(rating - mu)/(n()+lambda))

b_u_v <- edx %>% 
  left_join(b_i_v, by="movieId") %>%
  group_by(userId) %>%
  summarize(b_u_v = sum(rating - b_i_v - mu)/(n()+lambda))

b_g_v <- edx %>%
  left_join(b_i_v, by="movieId") %>%
  left_join(b_u_v, by="userId") %>%
  group_by(genres) %>%
  summarise(b_g_v = sum(rating - b_i_v - b_u_v - mu)/(n()+lambda))

predicted_ratings <- 
  validation %>% 
  left_join(b_i_v, by = "movieId") %>%
  left_join(b_u_v, by = "userId") %>%
  left_join(b_g_v, by = "genres") %>%
  mutate(pred = mu + b_i_v + b_u_v + b_g_v) %>%
  pull(pred)

rsme_final_validation <- RMSE(predicted_ratings,validation$rating)
rmse_validation <-  data_frame(method = "Validate Regularised average + b_i + b_u + b_g", RMSE = rsme_final_validation)
knitr::kable (rmse_validation, caption = "RSME validation")
```

```{r validate matrix factorization, echo = FALSE,  cache = TRUE}

#Validation factorization

if(!require(recosystem)) 
  install.packages("recosystem", repos = "http://cran.us.r-project.org")
set.seed(2022, sample.kind = "Rounding") # This is a randomized algorithm

# Convert 'edx' and 'validation' sets to recosystem input format
edx_reco <-  with(edx, data_memory(user_index = userId, 
                                   item_index = movieId, 
                                   rating = rating))
validation_reco  <-  with(validation, data_memory(user_index = userId, 
                                                  item_index = movieId, 
                                                  rating = rating))

# Create the model object
r <-  recosystem::Reco()

# Tune the parameters
opts <-  r$tune(edx_reco, opts = list(dim = c(10, 20, 30), 
                                      lrate = c(0.1, 0.2),
                                      costp_l2 = c(0.01, 0.1), 
                                      costq_l2 = c(0.01, 0.1),
                                      nthread  = 4, niter = 10))

# Train the model
r$train(edx_reco, opts = c(opts$min, nthread = 4, niter = 20))

# Calculate the prediction
y_hat_final_reco <-  r$predict(validation_reco, out_memory())

rsme_reco_validation <- RMSE(y_hat_final_reco,validation$rating)

rsme_reco_validation

rmse_validation <-  bind_rows(rmse_validation, data_frame(method = "Validate matrix factorization", RMSE = rsme_reco_validation))
knitr::kable (rmse_validation, caption = "RSME validation with Matrix Factorization")


```


# Conclusion

The model using the regularized on movies, users and genres effect can achieve RMSE of 0.8644514 whereas the matrix factorization model can achieve RMSE of 0.7826499.

The limitation is the computing power of personal laptop on the very large dataset which the recommenderlab package cannot be implemented in this report. It has various algorithms to estimate the ratings. 

Future works with more computing power, recommenderlab can be tried.


